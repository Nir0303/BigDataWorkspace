{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.15:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.2.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[4]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[4] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark-metastore\",\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 42016\r\n",
      "-rw-rw-r-- 1 niranjan niranjan     5272 Mar 11 12:00 201508_station_data.csv\r\n",
      "-rw-rw-r-- 1 niranjan niranjan 43012650 Mar 11 12:00 201508_trip_data.csv\r\n"
     ]
    }
   ],
   "source": [
    "ls -ltr ../../data/bike-data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "less ../../data/bike-data/201508_trip_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "trip_raw_df = spark.read \\\n",
    "                .format(\"csv\") \\\n",
    "                .option(\"header\",\"true\") \\\n",
    "                .option(\"inferSchema\",\"true\") \\\n",
    "                .load(\"../../data/bike-data/201508_trip_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_raw_df = spark.read \\\n",
    "                    .format(\"csv\") \\\n",
    "                    .option(\"header\",\"true\") \\\n",
    "                    .option(\"inferSchema\",\"true\") \\\n",
    "                    .load(\"../../data/bike-data/201508_station_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip ID: integer (nullable = true)\n",
      " |-- Duration: integer (nullable = true)\n",
      " |-- Start Date: string (nullable = true)\n",
      " |-- Start Station: string (nullable = true)\n",
      " |-- Start Terminal: integer (nullable = true)\n",
      " |-- End Date: string (nullable = true)\n",
      " |-- End Station: string (nullable = true)\n",
      " |-- End Terminal: integer (nullable = true)\n",
      " |-- Bike #: integer (nullable = true)\n",
      " |-- Subscriber Type: string (nullable = true)\n",
      " |-- Zip Code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- dockcount: integer (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- installation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "station_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- trip_id: integer (nullable = true)\n",
      " |-- duration: integer (nullable = true)\n",
      " |-- start_date: string (nullable = true)\n",
      " |-- start_station: string (nullable = true)\n",
      " |-- start_terminal: integer (nullable = true)\n",
      " |-- end_date: string (nullable = true)\n",
      " |-- end_station: string (nullable = true)\n",
      " |-- end_terminal: integer (nullable = true)\n",
      " |-- bike: integer (nullable = true)\n",
      " |-- subscriber_type: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "trip_columns = [col(i).alias(i.lower().replace(\" #\",\"\").replace(\" \",\"_\")) for i in trip_raw_df.columns]\n",
    "trip_df = trip_raw_df.select(trip_columns)\n",
    "trip_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- station_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- lat: double (nullable = true)\n",
      " |-- long: double (nullable = true)\n",
      " |-- dockcount: integer (nullable = true)\n",
      " |-- landmark: string (nullable = true)\n",
      " |-- installation: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "station_columns = [col(i).alias(i.lower().replace(\" \",\"_\")) for i in station_raw_df.columns]\n",
    "station_df = station_raw_df.select(station_columns)\n",
    "station_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "Populating the interactive namespace from numpy and matplotlib\n",
      "+-------+--------+---------------+------------------------------------+--------------+---------------+----------------------------------------+------------+----+---------------+--------+\n",
      "|trip_id|duration|start_date     |start_station                       |start_terminal|end_date       |end_station                             |end_terminal|bike|subscriber_type|zip_code|\n",
      "+-------+--------+---------------+------------------------------------+--------------+---------------+----------------------------------------+------------+----+---------------+--------+\n",
      "|913460 |765     |8/31/2015 23:26|Harry Bridges Plaza (Ferry Building)|50            |8/31/2015 23:39|San Francisco Caltrain (Townsend at 4th)|70          |288 |Subscriber     |2139    |\n",
      "|913459 |1036    |8/31/2015 23:11|San Antonio Shopping Center         |31            |8/31/2015 23:28|Mountain View City Hall                 |27          |35  |Subscriber     |95032   |\n",
      "+-------+--------+---------------+------------------------------------+--------------+---------------+----------------------------------------+------------+----+---------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip_df.show(2,truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------------------------+---------+-----------+---------+--------+------------+\n",
      "|station_id|name                             |lat      |long       |dockcount|landmark|installation|\n",
      "+----------+---------------------------------+---------+-----------+---------+--------+------------+\n",
      "|2         |San Jose Diridon Caltrain Station|37.329732|-121.901782|27       |San Jose|8/6/2013    |\n",
      "|3         |San Jose Civic Center            |37.330698|-121.888979|15       |San Jose|8/5/2013    |\n",
      "+----------+---------------------------------+---------+-----------+---------+--------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "station_df.show(2,False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "favoriate or most visited station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "most_visited_df = trip_df.groupBy(\"end_station\")\\\n",
    "                            .count()\\\n",
    "                            .withColumnRenamed(\"count\",\"visits\")\\\n",
    "                            .sort(desc(\"visits\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*Sort [visits#423L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(visits#423L DESC NULLS LAST, 200)\n",
      "   +- *HashAggregate(keys=[end_station#199], functions=[count(1)])\n",
      "      +- Exchange hashpartitioning(end_station#199, 200)\n",
      "         +- *HashAggregate(keys=[end_station#199], functions=[partial_count(1)])\n",
      "            +- *Project [End Station#126 AS end_station#199]\n",
      "               +- *FileScan csv [End Station#126] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/niranjan/working/BigDataWorkspace/data/bike-data/201508_trip_data.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<End Station:string>\n"
     ]
    }
   ],
   "source": [
    "most_visited_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------------+------+\n",
      "|end_station                                  |visits|\n",
      "+---------------------------------------------+------+\n",
      "|San Francisco Caltrain (Townsend at 4th)     |34810 |\n",
      "|San Francisco Caltrain 2 (330 Townsend)      |22523 |\n",
      "|Harry Bridges Plaza (Ferry Building)         |17810 |\n",
      "|2nd at Townsend                              |15463 |\n",
      "|Townsend at 7th                              |15422 |\n",
      "|Embarcadero at Sansome                       |15065 |\n",
      "|Market at Sansome                            |13916 |\n",
      "|Steuart at Market                            |13617 |\n",
      "|Temporary Transbay Terminal (Howard at Beale)|12966 |\n",
      "|Powell Street BART                           |10239 |\n",
      "|Market at 10th                               |10220 |\n",
      "|Market at 4th                                |9685  |\n",
      "|2nd at South Park                            |8253  |\n",
      "|5th at Howard                                |8147  |\n",
      "|Civic Center BART (7th at Market)            |7714  |\n",
      "|Howard at 2nd                                |7275  |\n",
      "|Embarcadero at Folsom                        |7229  |\n",
      "|Broadway St at Battery St                    |7159  |\n",
      "|Embarcadero at Bryant                        |6687  |\n",
      "|Beale at Market                              |6330  |\n",
      "+---------------------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_visited_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "most visited landmark or destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count,countDistinct\n",
    "most_visited_landmark_df = trip_df.join(station_df, col(\"end_terminal\")==col(\"station_id\"),\"inner\")\\\n",
    "                                .groupBy(\"landmark\",\"subscriber_type\")\\\n",
    "                                .agg(count(\"station_id\"),countDistinct(\"end_terminal\"))\\\n",
    "                                .sort(desc(\"count(station_id)\")) \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*Sort [count(station_id)#2395L DESC NULLS LAST], true, 0\n",
      "+- Exchange rangepartitioning(count(station_id)#2395L DESC NULLS LAST, 200)\n",
      "   +- *HashAggregate(keys=[landmark#221, subscriber_type#202], functions=[count(station_id#216), count(distinct end_terminal#200)])\n",
      "      +- Exchange hashpartitioning(landmark#221, subscriber_type#202, 200)\n",
      "         +- *HashAggregate(keys=[landmark#221, subscriber_type#202], functions=[merge_count(station_id#216), partial_count(distinct end_terminal#200)])\n",
      "            +- *HashAggregate(keys=[landmark#221, subscriber_type#202, end_terminal#200], functions=[merge_count(station_id#216)])\n",
      "               +- Exchange hashpartitioning(landmark#221, subscriber_type#202, end_terminal#200, 200)\n",
      "                  +- *HashAggregate(keys=[landmark#221, subscriber_type#202, end_terminal#200], functions=[partial_count(station_id#216)])\n",
      "                     +- *BroadcastHashJoin [end_terminal#200], [station_id#216], Inner, BuildRight\n",
      "                        :- *Filter isnotnull(end_terminal#200)\n",
      "                        :  +- InMemoryTableScan [end_terminal#200, subscriber_type#202], [isnotnull(end_terminal#200)]\n",
      "                        :        +- InMemoryRelation [trip_id#193, duration#194, start_date#195, start_station#196, start_terminal#197, end_date#198, end_station#199, end_terminal#200, bike#201, subscriber_type#202, zip_code#203], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                        :              +- *Project [Trip ID#120 AS trip_id#193, Duration#121 AS duration#194, Start Date#122 AS start_date#195, Start Station#123 AS start_station#196, Start Terminal#124 AS start_terminal#197, End Date#125 AS end_date#198, End Station#126 AS end_station#199, End Terminal#127 AS end_terminal#200, Bike ##128 AS bike#201, Subscriber Type#129 AS subscriber_type#202, Zip Code#130 AS zip_code#203]\n",
      "                        :                 +- *FileScan csv [Trip ID#120,Duration#121,Start Date#122,Start Station#123,Start Terminal#124,End Date#125,End Station#126,End Terminal#127,Bike ##128,Subscriber Type#129,Zip Code#130] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/niranjan/working/BigDataWorkspace/data/bike-data/201508_trip_data.csv], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Trip ID:int,Duration:int,Start Date:string,Start Station:string,Start Terminal:int,End Dat...\n",
      "                        +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)))\n",
      "                           +- *Filter isnotnull(station_id#216)\n",
      "                              +- InMemoryTableScan [station_id#216, landmark#221], [isnotnull(station_id#216)]\n",
      "                                    +- InMemoryRelation [station_id#216, name#217, lat#218, long#219, dockcount#220, landmark#221, installation#222], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                                          +- *FileScan csv [station_id#155,name#156,lat#157,long#158,dockcount#159,landmark#160,installation#161] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/home/niranjan/working/BigDataWorkspace/data/bike-data/201508_station_data..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<station_id:int,name:string,lat:double,long:double,dockcount:int,landmark:string,installati...\n"
     ]
    }
   ],
   "source": [
    "most_visited_landmark_df.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[station_id: int, name: string, lat: double, long: double, dockcount: int, landmark: string, installation: string]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trip_df.cache()\n",
    "station_df.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+-----------------+----------------------------+\n",
      "|landmark     |subscriber_type|count(station_id)|count(DISTINCT end_terminal)|\n",
      "+-------------+---------------+-----------------+----------------------------+\n",
      "|San Francisco|Subscriber     |282477           |35                          |\n",
      "|San Francisco|Customer       |38633            |35                          |\n",
      "|San Jose     |Subscriber     |15440            |16                          |\n",
      "|Mountain View|Subscriber     |8751             |7                           |\n",
      "|San Jose     |Customer       |2515             |16                          |\n",
      "|Palo Alto    |Subscriber     |1878             |5                           |\n",
      "|Redwood City |Subscriber     |1671             |7                           |\n",
      "|Palo Alto    |Customer       |1235             |5                           |\n",
      "|Mountain View|Customer       |1228             |7                           |\n",
      "|Redwood City |Customer       |324              |7                           |\n",
      "+-------------+---------------+-----------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_visited_landmark_df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
